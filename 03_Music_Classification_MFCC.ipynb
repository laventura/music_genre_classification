{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Genre Classification - with MFCC\n",
    "\n",
    "TODO - add readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "\n",
    "# signal processing\n",
    "from scipy.io                     import wavfile\n",
    "from scipy                        import stats, signal\n",
    "from scipy.fftpack                import fft\n",
    "\n",
    "from scipy.signal                 import lfilter, hamming\n",
    "from scipy.fftpack.realtransforms import dct\n",
    "\n",
    "# lib for music processing\n",
    "import librosa as lr\n",
    "\n",
    "# general purpose\n",
    "import collections\n",
    "\n",
    "# plotting\n",
    "from   numpy.lib                  import stride_tricks\n",
    "import matplotlib        as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns\n",
    "\n",
    "from IPython.display              import HTML\n",
    "from base64                       import b64encode\n",
    "\n",
    "# Classification and evaluation\n",
    "from sklearn.preprocessing        import StandardScaler\n",
    "from sklearn                      import svm\n",
    "from sklearn.cross_validation     import StratifiedKFold, ShuffleSplit, cross_val_score\n",
    "from sklearn.naive_bayes          import GaussianNB\n",
    "from sklearn.neighbors            import KNeighborsClassifier\n",
    "from sklearn.ensemble             import RandomForestClassifier\n",
    "from sklearn.metrics              import classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# figure size\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atul Acharya 2016-12-16 \n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 5.0.0\n",
      "\n",
      "librosa 0.4.3\n",
      "sklearn 0.18.1\n",
      "seaborn 0.7.1\n",
      "scipy 0.18.1\n",
      "numpy 1.11.2\n",
      "\n",
      "compiler   : GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.54)\n",
      "system     : Darwin\n",
      "release    : 15.6.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Atul Acharya' -d -m -v -p librosa,sklearn,seaborn,scipy,numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GZTAN Dataset \n",
    "DATA_DIR = '/Users/aa/Developer/datasets/music_genre/genres'\n",
    "GENRES_DIR = '/Users/aa/Developer/datasets/music_genre/genres'\n",
    "GENRES_LIST = ['blues', 'classical', 'country', 'disco', 'hiphop',\n",
    "                'jazz', 'metal', 'pop', 'rock', 'reggae' ]\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's see how many files are there\n",
    "def print_files(genre_list, base_dir=GENRES_DIR, ftype='*.wav'):\n",
    "    for label, genre in enumerate(genre_list):\n",
    "        flist =  glob.glob(os.path.join(base_dir, genre, ftype))\n",
    "        print('dir: {0:10s} ==> #files {1}'.format(genre, len(flist) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir: blues      ==> #files 100\n",
      "dir: classical  ==> #files 100\n",
      "dir: country    ==> #files 100\n",
      "dir: disco      ==> #files 100\n",
      "dir: hiphop     ==> #files 100\n",
      "dir: jazz       ==> #files 100\n",
      "dir: metal      ==> #files 100\n",
      "dir: pop        ==> #files 100\n",
      "dir: rock       ==> #files 100\n",
      "dir: reggae     ==> #files 100\n"
     ]
    }
   ],
   "source": [
    "print_files(GENRES_LIST, GENRES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Create a MFCC-CEPS dataset\n",
    "\n",
    "def write_mfcc(mfcc_ceps, fname):\n",
    "    ''' Write the MFCC of the given wavefilename\n",
    "    '''\n",
    "    base_fn, ext = os.path.splitext(fname)\n",
    "    data_fn = base_fn + '.mfcc'\n",
    "    np.save(data_fn, mfcc_ceps)\n",
    "    \n",
    "def calc_mfcc_ceps(filename):\n",
    "    ''' Calc MFCC Ceps of the give wavefilename, using librosa\n",
    "    '''\n",
    "    # load the file via librosa\n",
    "    signal, sample_rate = librosa.load(filename)\n",
    "    # extract MFCC; get only the 20 features\n",
    "    mfcc = librosa.feature.mfcc(y=signal, \n",
    "                               sr=sample_rate,\n",
    "                               n_mfcc=20)\n",
    "    # this will be of shape [13 x Num_of_samples ]\n",
    "    # we want to transpose it\n",
    "    mfcc_t = mfcc.T\n",
    "    write_mfcc(mfcc_t, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aa/Developer/datasets/music_genre/genres/rock/rock.00093.au.wav\n"
     ]
    }
   ],
   "source": [
    "sample_file = os.path.join(GENRES_DIR, 'rock', 'rock.00093.au.wav')\n",
    "\n",
    "print(sample_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calc_mfcc_ceps(sample_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aa/Developer/datasets/music_genre/genres/rock/rock.00093.au.mfcc.npy\n",
      "(1293, 20)\n"
     ]
    }
   ],
   "source": [
    "b, e = os.path.splitext(sample_file)\n",
    "m1 = b + '.mfcc.npy'\n",
    "print(m1)\n",
    "t1 = np.load(m1)\n",
    "print(t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an MFCC CEPS dataset -- IGnore this step if dataset already created!!\n",
    "from pyprind import ProgBar\n",
    "\n",
    "def create_ceps_dataset(base_dir):\n",
    "    ''' Create + save cepstral MFCC for all the WAV files in the base_dir\n",
    "    '''\n",
    "    print('Creating MFCC ceps for', base_dir)\n",
    "    for path, dirs, _ in os.walk(base_dir):\n",
    "        print(dirs)\n",
    "        for d in dirs:\n",
    "            glob_wav = os.path.join(path + '/' + d, \"*.wav\")\n",
    "            files = glob.glob(glob_wav)\n",
    "            print('In {0} are {1} wav files'.format(d, len(files)))\n",
    "            progbar = ProgBar(len(files))\n",
    "            for f in files:\n",
    "                calc_mfcc_ceps(f)\n",
    "                progbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[                              ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MFCC ceps for /Users/aa/Developer/datasets/music_genre/genres\n",
      "['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
      "In blues are 100 wav files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:07\n",
      "0%                          100%\n",
      "[                              ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In classical are 100 wav files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n",
      "0%                          100%\n",
      "[                              ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In country are 100 wav files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n",
      "0%                          100%\n",
      "[                              ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In disco are 100 wav files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n",
      "0%                          100%\n",
      "[                              ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In hiphop are 100 wav files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n",
      "0%                          100%\n",
      "[                              ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In jazz are 100 wav files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n",
      "0%                          100%\n",
      "[                              ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In metal are 100 wav files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n",
      "0%                          100%\n",
      "[                              ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In pop are 100 wav files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n",
      "0%                          100%\n",
      "[                              ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In reggae are 100 wav files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n",
      "0%                          100%\n",
      "[                              ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In rock are 100 wav files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############################] | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:08\n"
     ]
    }
   ],
   "source": [
    "create_ceps_dataset(GENRES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Now read the MFCC CEPS files\n",
    "def read_ceps(genre_list, base_dir=GENRES_DIR):\n",
    "    '''  Read the MFCC Cepstral coefficients for all files in base_dir, and given list of genres\n",
    "        \n",
    "        Returns:\n",
    "        X:  dataset of cepstral coefficients. Shape [13 x Num_of_samples]\n",
    "        Y:  label of the directory (one-hot encoded)\n",
    "    '''\n",
    "    X = []\n",
    "    y = []\n",
    "    for label, genre in enumerate(genre_list):\n",
    "        for fname in glob.glob(os.path.join(base_dir, genre, \"*.mfcc.npy\")):\n",
    "            ceps = np.load(fname)\n",
    "            if np.any(np.isnan(ceps)):\n",
    "                print('!!!! NaN values in', fn)\n",
    "                #print(ceps)\n",
    "                continue\n",
    "            else:\n",
    "                num_ceps = len(ceps)\n",
    "                # dampen the CEPS -- by taking 10% off from beginning and end of track\n",
    "                X.append(\n",
    "                    np.mean(ceps[int(num_ceps / 10):int(num_ceps * 9 / 10)], axis=0))\n",
    "                y.append(label)\n",
    "                \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = read_ceps(GENRES_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.11997148e+02   1.21238132e+02  -1.77501054e+01 ...,  -1.83897536e-01\n",
      "   -1.66692947e+00   1.81544513e+00]\n",
      " [ -1.99126220e+02   1.24311799e+02   7.81554181e+00 ...,   4.59839435e-02\n",
      "   -2.60645420e-01   3.45716552e-01]\n",
      " [ -8.98784562e+01   1.42878391e+02  -2.96622420e+01 ...,  -2.07295617e+00\n",
      "   -3.28526325e+00  -1.95531306e+00]\n",
      " ..., \n",
      " [ -1.45343071e+02   1.03287670e+02  -1.64123941e+01 ...,   3.40847265e-01\n",
      "    2.60661905e+00   2.54865509e+00]\n",
      " [ -1.35048214e+02   9.36368560e+01   8.60264646e+00 ...,   3.04042890e-01\n",
      "    5.75803510e-01  -1.50165265e-01]\n",
      " [ -6.96691994e+01   8.17856429e+01  -4.24591176e+01 ...,   4.19294482e+00\n",
      "   -1.05298231e+00  -2.99687541e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the MFCCs before Fitting the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##  Do a Train/Test split\n",
    "sp = ShuffleSplit(X.shape[0],   # num of tracks\n",
    "                 n_iter=1,\n",
    "                 test_size=0.25)  # 25% test\n",
    "train_split, test_split = zip(*sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Classifier  test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 20)\n",
      "(250, 20)\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "X_train, y_train = X[train_split], y[train_split]\n",
    "X_test, y_test   = X[test_split], y[test_split]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Scale the data!! \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdscaler = StandardScaler()\n",
    "\n",
    "stdscaler.fit(X_train)\n",
    "X_train_std = stdscaler.transform(X_train)\n",
    "X_test_std  = stdscaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Train / fit the model\n",
    "tf = knn_clf.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_score = knn_clf.score(X_train_std, y_train)\n",
    "test_score = knn_clf.score(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998666666667\n",
      "0.568\n"
     ]
    }
   ],
   "source": [
    "print(train_score)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  0  1  1  0  0  3  0  1  0]\n",
      " [ 0 22  0  0  0  1  0  0  0  0]\n",
      " [ 1  1 12  2  1  2  0  0  5  2]\n",
      " [ 1  1  2 14  3  0  0  2  5  3]\n",
      " [ 1  0  0  2 11  2  0  0  4  5]\n",
      " [ 0  3  2  0  2 15  0  4  2  1]\n",
      " [ 4  0  0  0  1  0 13  0  2  0]\n",
      " [ 0  0  1  1  2  0  0 11  1  0]\n",
      " [ 2  0  0  3  4  0  1  3 12  0]\n",
      " [ 1  1  1  2  7  0  0  3  2 14]]\n"
     ]
    }
   ],
   "source": [
    "# get predictions -- to print confusion matrix\n",
    "y_pred = knn_clf.predict(X_test_std)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Let's Plot Confusion Matrix\n",
    "## Plot Confusion Matrix\n",
    "def plot_confusion_matrix(cmatrix, genre_list, name, title):\n",
    "    plt.figure(num=None, figsize=(10, 10))\n",
    "    plt.matshow(cmatrix, fignum=False, cmap='Blues', vmin=0, vmax=1.0)\n",
    "    ax = plt.axes()\n",
    "    ax.set_xticks(range(len(genre_list)))\n",
    "    ax.set_xticklabels(genre_list)\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    ax.set_yticks(range(len(genre_list)))\n",
    "    ax.set_yticklabels(genre_list)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.ylabel('True class')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAJGCAYAAAByRHCHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZmZmdXAlSozMzOzGvwNQniowU+aSwsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112e50048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalize the CM\n",
    "cm_avg = cm   # np.mean(cm, axis=0)\n",
    "cm_norm = cm_avg / np.sum(cm_avg, axis=0)\n",
    "plot_confusion_matrix(cm_norm, GENRES_LIST, 'KNN=1', 'Conf. Matrix of KNN=1 classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.998666666667\n",
      "Test score 0.552\n",
      "[[16  0  1  1  0  0  4  1  1  0]\n",
      " [ 0 20  0  0  1  2  0  0  0  0]\n",
      " [ 1  1 12  0  1  3  0  0  6  2]\n",
      " [ 1  1  3 16  2  0  0  1  6  1]\n",
      " [ 1  0  2  2 11  2  0  0  4  3]\n",
      " [ 0  3  2  1  1 16  0  3  2  1]\n",
      " [ 4  0  0  0  1  0 13  0  2  0]\n",
      " [ 0  0  1  1  2  0  0 10  2  0]\n",
      " [ 2  0  1  3  3  0  1  2 12  1]\n",
      " [ 1  1  2  2  7  2  0  2  2 12]]\n"
     ]
    }
   ],
   "source": [
    "## Try another scaler:\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "robust = RobustScaler()\n",
    "X_train_rb = robust.fit_transform(X_train)\n",
    "X_test_rb  = robust.transform(X_test)\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "## Train / fit the model\n",
    "tf = knn_clf.fit(X_train_rb, y_train)\n",
    "\n",
    "# score\n",
    "train_score = knn_clf.score(X_train_rb, y_train)\n",
    "test_score = knn_clf.score(X_test_rb, y_test)\n",
    "\n",
    "print('Train score', train_score)\n",
    "print('Test score', test_score)\n",
    "\n",
    "# get predictions -- to print confusion matrix\n",
    "y_pred = knn_clf.predict(X_test_rb)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45 (+/- 0.14)\n"
     ]
    }
   ],
   "source": [
    "# Try a cross validation\n",
    "cvfold = StratifiedKFold(y, n_folds=10)\n",
    "\n",
    "scores = cross_val_score(knn_clf, \n",
    "                         X,\n",
    "                         y, \n",
    "                         scoring='accuracy',\n",
    "                         cv=cvfold)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n",
      "(1000,)\n",
      "Starting CV...\n",
      "*** Using clf: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "Score: 0.51\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: GaussianNB(priors=None)\n",
      "Score: 0.43\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: SVC(C=0.3, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Score: 0.53\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n",
      "Score: 0.55\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "Score: 0.55\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: GaussianNB(priors=None)\n",
      "Score: 0.43\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: SVC(C=0.3, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Score: 0.58\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n",
      "Score: 0.61\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "Score: 0.46\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: GaussianNB(priors=None)\n",
      "Score: 0.4\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: SVC(C=0.3, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Score: 0.5\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n",
      "Score: 0.54\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "Score: 0.62\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: GaussianNB(priors=None)\n",
      "Score: 0.49\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: SVC(C=0.3, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Score: 0.58\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n",
      "Score: 0.56\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "Score: 0.57\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: GaussianNB(priors=None)\n",
      "Score: 0.35\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: SVC(C=0.3, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Score: 0.6\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n",
      "Score: 0.63\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "Score: 0.53\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: GaussianNB(priors=None)\n",
      "Score: 0.43\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: SVC(C=0.3, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Score: 0.55\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n",
      "Score: 0.48\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "Score: 0.49\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: GaussianNB(priors=None)\n",
      "Score: 0.42\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: SVC(C=0.3, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Score: 0.53\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n",
      "Score: 0.56\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "Score: 0.54\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: GaussianNB(priors=None)\n",
      "Score: 0.42\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: SVC(C=0.3, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Score: 0.58\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n",
      "Score: 0.57\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "Score: 0.54\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: GaussianNB(priors=None)\n",
      "Score: 0.49\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: SVC(C=0.3, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Score: 0.68\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n",
      "Score: 0.69\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "Score: 0.54\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: GaussianNB(priors=None)\n",
      "Score: 0.35\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: SVC(C=0.3, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Score: 0.55\n",
      "--------------------------------------------------------------------------------\n",
      "*** Using clf: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n",
      "Score: 0.52\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## Ensemble learning -- run experiments with different classifiers\n",
    "\n",
    "# read dataset again\n",
    "X, y = read_ceps(GENRES_LIST)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "classifiers = {}\n",
    "\n",
    "classifiers[\"GNB\"]        = GaussianNB()\n",
    "classifiers[\"svm_linear\"] = svm.SVC(kernel='linear', C=0.3)\n",
    "classifiers['knn'] = KNeighborsClassifier(n_neighbors=1)\n",
    "classifiers['RF']  = RandomForestClassifier(n_estimators=10,\n",
    "                                           criterion='gini',\n",
    "                                           n_jobs=-1)\n",
    "\n",
    "results = {}\n",
    "\n",
    "print('Starting CV...')\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "for train_ix, test_ix in skf.split(X, y):\n",
    "    X_train, y_train = X[train_ix], y[train_ix]\n",
    "    X_test,  y_test  = X[test_ix],  y[test_ix]\n",
    "    \n",
    "    stdscaler = StandardScaler()\n",
    "    X_train_std = stdscaler.fit_transform(X_train)\n",
    "    X_test_std  = stdscaler.transform(X_test)\n",
    "    \n",
    "    for c_name, clf in classifiers.items():\n",
    "        print('*** Using clf:', clf)\n",
    "        if c_name not in results:\n",
    "            results[c_name] = []\n",
    "        # train the classifier\n",
    "        clf.fit(X_train_std, y_train)\n",
    "        # get score\n",
    "        score = clf.score(X_test_std, y_test)\n",
    "        print('Score:', score)\n",
    "        print('-'*80)\n",
    "        \n",
    "        results[c_name].append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RF': [0.51000000000000001, 0.55000000000000004, 0.46000000000000002, 0.62, 0.56999999999999995, 0.53000000000000003, 0.48999999999999999, 0.54000000000000004, 0.54000000000000004, 0.54000000000000004], 'GNB': [0.42999999999999999, 0.42999999999999999, 0.40000000000000002, 0.48999999999999999, 0.34999999999999998, 0.42999999999999999, 0.41999999999999998, 0.41999999999999998, 0.48999999999999999, 0.34999999999999998], 'svm_linear': [0.53000000000000003, 0.57999999999999996, 0.5, 0.57999999999999996, 0.59999999999999998, 0.55000000000000004, 0.53000000000000003, 0.57999999999999996, 0.68000000000000005, 0.55000000000000004], 'knn': [0.55000000000000004, 0.60999999999999999, 0.54000000000000004, 0.56000000000000005, 0.63, 0.47999999999999998, 0.56000000000000005, 0.56999999999999995, 0.68999999999999995, 0.52000000000000002]}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF</th>\n",
       "      <th>GNB</th>\n",
       "      <th>svm_linear</th>\n",
       "      <th>knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.5</td>\n",
       "      <td>42.1</td>\n",
       "      <td>56.8</td>\n",
       "      <td>57.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.5</td>\n",
       "      <td>42.1</td>\n",
       "      <td>56.8</td>\n",
       "      <td>57.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.5</td>\n",
       "      <td>42.1</td>\n",
       "      <td>56.8</td>\n",
       "      <td>57.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.5</td>\n",
       "      <td>42.1</td>\n",
       "      <td>56.8</td>\n",
       "      <td>57.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.5</td>\n",
       "      <td>42.1</td>\n",
       "      <td>56.8</td>\n",
       "      <td>57.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     RF   GNB  svm_linear   knn\n",
       "0  53.5  42.1        56.8  57.1\n",
       "1  53.5  42.1        56.8  57.1\n",
       "2  53.5  42.1        56.8  57.1\n",
       "3  53.5  42.1        56.8  57.1\n",
       "4  53.5  42.1        56.8  57.1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_data = []\n",
    "\n",
    "for i in range(5):\n",
    "    rd = []\n",
    "    for cf in classifiers.keys():\n",
    "        vals = results[cf]\n",
    "        rd.append(np.mean(vals) * 100)\n",
    "    \n",
    "    results_data.append(rd)\n",
    "\n",
    "pd.DataFrame(np.asarray(results_data), columns=classifiers.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:  NORMALIZE THE MFCCs!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
